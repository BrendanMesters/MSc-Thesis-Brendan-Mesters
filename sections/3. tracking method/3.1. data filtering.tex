\section{Data filtering}
\label{section: tracking method - data filtering}

One issue present with the mmWave Sensors (in our experience) is the fact that they are susceptible to both environmental noise as well as seemingly random noise. 
This noise often occurred in "streaks", lines of points through your 3d space. 
These "streaks" were not very dense spatially and usually only existed for a single frame, they often formed in the general shape of a line, though never exactly so, see \cref{figure: noise streak}.
Due to these attributes, a combination of a temporal as well as a spatial filter was used to filter out the noise points.
% I could've used a temporal DBSCAN algorithm

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{figures/internal data/noise streak.png}
    \caption{A noise streak in the data (right-hand side of image)}
    \label{figure: noise streak}
\end{figure}

Many sophisticated systems for pointcloud filtering exist \cite{ester1996dbscan, faisal2017density}, however, most of these systems are built for Lidar, which has a significantly higher number of points. 
Even papers describing methods for "sparse pointclouds" reason about thousands of points at a time, as opposed to the dozens of points encountered in mmWave data.
This makes mmWave pointcloud denoising a truly separate problem, as is evident by the dataset produced specifically for this problem \cite{farella2019sparse} by \citeauthor{farella2019sparse}.
For these reasons, IAmMuse implements its own noise filters, built upon knn.

For this section, it's useful to know that the MMWave produces roughly 10 frames per second, thus each frame is roughly 100 ms.

\subsection{Spatial Filtering}
\label{sub-section: tracking method - data filtering - density filtering}

A common strategy for filtering spatial data is to look at the density and internal cohesion between points.
The main idea on which this is based is the assumption that points with \textit{many close neighbors} are likely to \textit{represent reality well}, a "strength in numbers" kind of philosophy.
IAmMuse uses \textit{spatial filtering} that considers the clustering of points on a \textit{frame-by-frame basis}.
Each point gets assigned a \textit{density score} based on the cumulative weight of its neighbors (points with a distance < 25 cm). 
If their \textit{density score} exceeds a certain (configurable) threshold, then the point is labeled as "signal", otherwise it is labeled as "noise".

The main task of spatial filtering in IAmMuse is to remove outliers, to always let dense clusters pass, and to give an indication of how important any sparse clusters are.
By using the cumulative weight of the neighbors of a point, we also ensure that points that have already been shown to be more likely to be of use by different systems (such as the one described in \cref{sub-section: tracking method - data enhancement - minimal enclosing ball}) will be more likely to be labeled as "signal".
One type of noise that the spatial filtering does not handle well, however, is dense but brief noise spikes.
Since our spatial filtering method only takes into account the point density within a single frame, it's not able to discern between these noise spikes and the actual signal, and that is why the system also uses \textit{temporal filtering}.

% We also filter on the density in a single frame, since high in-frame consistency also often shows high quality of the data.
% However, sometimes noise streaks are dense enough to falsely trigger this system.


\subsection{Temporal Filtering}
\label{sub-section: tracking method - data filtering - temporal filtering}
The main task of the \textit{temporal filter} in IAmMuse is to provide stability across frames and to detect and remove noise spikes.
The temporal filter achieves this in a very similar way to the spatial filter, but instead of looking for neighbors (nearby points) in the same frame, it only considers neighbors in a configurable number of earlier frames.
More specifically, IAmMuse's temporal filter takes into consideration the three frames (0.3-0.4 seconds) that came before, it then gives each point a score equal to the cumulative weight of its neighbors (points within 20 cm) within these prior frames.
This means that points in a dense cloud may all get a very low score if little or no data has been found in that area recently.
In this way, the \textit{temporal filter} can filter out any inconsistent data, such as sudden but dense noise spikes.

Removing inconsistent data is not the only thing that the temporal filter does.
The temporal filter also gives a high score to, and thus selects, points in temporally stable areas more than the density filter would, because the temporal filter takes into account points of multiple frames.
This means that any data that is consistently present in an area across frames will be highly rated by the temporal filter, even though it takes into account a slightly smaller neighborhood (20 cm as opposed to the 25 cm of spatial filters).
That being said, on their own, temporal filters can often miss large amounts of data, since the MMWave sensor does not always produce temporally consistent data, as discussed in \cref{section: background - millimeter wave radar}.
That is why IAmMuse uses a combination of both a \textit{spatial} and a \textit{temporal} filter.


% Temporal data filtering was chosen, as the noise most often encountered was only present in a single frame. 
% By comparing the points in subsequent frames, these noise points can be filtered out by looking at the stability across frames.
% This was implemented by checking the number of neighbors on different frames that any point had within a specified distance (e.g., 10 cm). 
% In this case, even dense clusters on a single frame will be filtered out if this cluster is not present on other frames.
% 
% A danger of this approach is that you might lose correct points, this problem becomes more prevalent if the data is not always consistent over time.
% If the FMCW measures an arm (so not noise) in frames 1, 3, and 5, all that data will be discarded if we only consider a window of 3 frames (centered on the frame to be looked at, so on frame 3, we consider frames 2, 3, 4).
% Due to this side effect, it's important to choose the \textit{window of frames} you consider, as well as the \textit{minimum number of neighbors} and the \textit{distance within which you count as a neighbor}.


\subsection{Combined Filtering and Tuning}
\label{sub-section: tracking method - data filtering - combined filtering and tuning}

IAmMuse uses a combination of the \textit{spatial} and the \textit{temporal} filters, so that it can get the benefits of both while mitigating their weaknesses.
It does this by calculating both the \textit{density score} and the \textit{temporal score} for each point, and combining these, in accordance with an distribution scale. 
This \textit{combined score} is then compared to a threshold value, also composed of the two seperate threshold values combined through a distribution scale.
% where it combines their respective scores, to make use of the strengths of both, while mitigating the weaknesses of both.
Thus this combined filter has six variables which can be tuned: the number of frames considered in the temporal system; for both the \textit{spatial} \textbf{and} the \textit{temporal} filters, the neighborhood size considered, and the threshold value used to distinguish between noise an signal; and lastly the amount we take into account the spatial result or the temporal result, the \textit{distribution scale}.
Combining these two systems, however, does make it more difficult to tune, as there are more moving parts.
Therefore, a specific tuning strategy is used for IAmMuse, to get the system to a reasonable state, afterwards, small tweaks are still made to fine tune the system.
% Therefore, a specific tuning strategy was thought up beforehand to get the system to a reasonable state.
% Afterward, small tweaks were still made, based on what looked good to the visual inspection of the researcher.
% This is the main reason why we made a specific tuning strategy for this system before we started actually tuning it, though some manual tuning was still required in the end.

The tuning strategy which was used for this system was based on two principal ideas.
Firstly, the fact that the spatial filter is best at identifying most actual signal points, even if some noise comes through, this makes it a good starting point when trying to filter the data.
Secondly, the fact that the temporal filter is good at detecting these noise points which get past the spatial filtering, which makes it a good candidate to clean up the output of the spatial filter.
%In the combined filtering these two filters are both tuned to their strength, combined and finetuned to fit together well.
%that the spatial filtering would be best at getting our positive values, while still avoiding some outliers, and that the temporal filter would be able to provide enough of a counterbalance to mark inconsistent points as noise, while keeping the consistent points to be signal.

Our tuning strategy is thus to start by tuning the \textit{spatial filter} on its own in such a way that it captures all points we deem to be part of the signal, this means that it will also capture some points which are deemed to be noise.
The \textit{temporal filter} should then be tuned, once again on its own, in such a way that it must not capture any noise, even if this means missing some points which are part of the signal.
These two filters are then combined (starting with a 50-50 split of effectiveness), and fine-tuning will happen. 
The goal of this fine tuning is to increase the prevalence of the spatial filter if data points are being missed, or to increase the prevalence of the temporal filter if noise is being labeled as data.
This can be done by changing the \textit{distribution scale}, increasing the neighborhood of the filter which is not having enough effect, or decreasing the neighborhood size of the other filter. 
The \textit{threshold value} can also be changed by modifying the two threshold values which make it up, lowering or increasing it to increase or decrease the number of points labeled as data respectively
% v [ old ] v
% Here, the various variables will be modified slowly to resolve problems that are encountered.
% In general, if signal points are missed, we should want either to increase the neighborhood size of the spatial filter, lower its threshold, or make it more prevalent in the filter split.
% In a similar vein, if noise points are not identified as such, we will want to increase the prevalence of the temporal filter in the filter split, lower the temporal threshold, or decrease its neighborhood size.

A big advantage of this system is that it can be quickly tuned to the different scenario, since the output of mmWave sensors can differ quite drastically based on the physical setup of the sensor and its environment.
This means that a system can be moved around with relatively little effort when you compare it to systems based on deep learning.
If you are able to define a good quality-metric for a point cloud recording, then you might even be able to automate this tuning, due to the low number of input parameters to the system (6).

% Combined filters aim to make use of the best of both filters while mitigating the weaknesses of both filters.
% Tuning such a system is always an important part, the way this system was tuned was by first loosely tuning both systems, keeping in mind what we want from them.

% The density filter was tuned in such a way that it would recognize most actual hand recordings (with any significant number of points, e.g. 5-7 min) while letting through as few noise streaks as we can.

% The temporal filter was filtered in such a way that it notices a decent number of hand positions, while prioritizing filtering out noise streaks.

% So density should catch almost all hands, while temporal should ignore almost all noise.

% During the combination of both filters, we want to give enough weight to the temporal filter, to remove most noise streaks, but we want to not make it too great, so that we still recognize hand clusters which are only "good visible" in one frame.

% We tune the individual filters with Distance (for neighbor search) and the threshold neighbor value. And for temporal, we also use the number of frames considered (values between 3-7, where considered, though any number > 5 (~half a second) already risks being more noise than data).
% Lastly, we of course have to decide in what manner we want to combine both.

% The advantage of doing it this way is that you can "retune" if you're tackling a different scenario. e.g. a scenario with slow-moving hands will probably want to consider a higher number of frames, while one with fast-moving hands wants to consider fewer frames. So too you can make density filters more prevalent in your final filter if you don't encounter a lot of random noise, while you can lean more on temporal filters if you do.
