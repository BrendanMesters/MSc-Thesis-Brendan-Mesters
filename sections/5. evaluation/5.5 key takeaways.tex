\section{Key Takeaways}
\label{section: evaluation - key takeaways}

%     -[[ Base Comparison - Training Data ]]-
In this chapter, a few different trained MARS models have been compared with IAmMuse, but none of them could outperform IAmMuse in the position state predictions.
The only models that came close to a reasonable performance also needed a significant amount of data to achieve this, as can be seen in \cref{figure: accuracy vs training data}, which plots the accuracy of a model against the amount of training/initialization data.
This clearly shows that the MARS models do get better with more training data, however, this also shows that a well-designed algorithm outperforms the DL systems, even with little to no training/calibration.


\begin{figure}[!htb]
    \centering
    \includegraphics[width=0.8\linewidth]{figures/results/_accuracy vs training data.png}
    \caption{The accuracy for each model considered (y-axis) plotted against the amount of data it used (x-axis)}
    \label{figure: accuracy vs training data}
\end{figure}

%     -[[ Specific pitfalls of MARS models ]]-
The baseline, or apples-to-apples (a2a) model, which was trained on the calibration data of a single recording, performed very badly, as expected.
The MARS model, which was provided by the paper, did not perform significantly better, even though it had a larger training data set, this was most likely in part due to the fact that the specific data recording setup was different from the one used in IAmMuse, something Deep Learning models are often sensitive to.
Training the MARS model on all the calibration data yielded a bad result, also, the model seemed to get stuck in a local minima during training, where it held a static position, which minimized the MAE, as opposed to trying to react dynamically to the input data.
This was likely in part due to the properties of the calibration data.
The models where MARS were trained on a significant amount of \textit{usage data} performed the best. 
These models still suffered from the fact that they were very stuttery.
This was almost certainly caused by the stability issue with data from the mmWave Radar, which is discussed in \cref{section: background - millimeter wave radar}.

%     -[[ Conclusion ]]-
The IAmMuse system uses significantly less data and produces significantly better results.
Granted, IAmMuse tries to solve a more specific problem than MARS, but in many cases, a solid application-specific solution is better than a flaky general-purpose solution.
Many of the current shortcomings of IAmMuse, such as the need for calibration and the limited arm angles, are also not inherent and are likely to be solvable with follow-up research, this is further discussed in \cref{section: conclusion - future work}.
Al in al IAmMuse succeeded in showing the potential of algorithmic solutions to the human pose estimation application for millimeter wave radar data.
It was able to circumnavigate the low point density inherent to these chips by using domain knowledge to enhance the data, as well as using other tunable systems to solve issues that were encountered.
The various parts of the IAmMuse pipeline can also be inspected and tuned individually, making it feasible to move this system between different usage environments.

Thus, this thesis has succeeded in all the research challenges that were set out.
\begin{itemize}
    \item 
        An effective algorithmic interpretation method for mmWave radar pointclouds has been created. 
        This method interprets these pointclouds for use in Human Pose Estimation application.
    \item  
        The method created is explainable, as is shown by the explanation provided in \cref{chapter: tracking method}. 
        Furthermore, the system can also be tuned to work in changing circumstances.
    \item 
        The interpretation method provided exceeds the performance of a similar deep learning system, in the form of MARS.
\end{itemize}
With that, the authors believe this research to be a success.


% Mention performance of various Mars models
% With equal training, MARS performs super poorly
% Mars fell into a local maxima with config train
% Well-trained is better over the board
% Well-trained still suffers from similar issues as config train

% Start making a conclusion
% MARS had issues with {stability, certain positions}
% This is most likely due to
% IAmMuse didn't
% Only issue IAmMuse had was {zone specification}.

% Thus, IAmMuse is better.
