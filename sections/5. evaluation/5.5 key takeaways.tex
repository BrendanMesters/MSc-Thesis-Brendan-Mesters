\section{Key Takeaways}
\label{section: evaluation - key takeaways}

%     -[[ Base Comparison - Training Data ]]-
In this chapter, a few different trained MARS models have been compared with IAmMuse, none of them could outperform IAmMuse.
The models that produced a reasonable output also needed a significant amount of training data to achieve this, as can be seen in \cref{figure: accuracy vs training data}, which plots the accuracy of a model against the amount of training/initialization data.
This clearly shows that the MARS models do get better with more training data, however, it also shows that a well-designed algorithm (IAmMuse) can outperform the DL systems, even with little to no training/calibration.


\begin{figure}[!htb]
    \centering
    \includegraphics[width=0.8\linewidth]{figures/results/_accuracy vs training data.png}
    \caption{The accuracy for each model considered (y-axis) plotted against the amount of data it used (x-axis)}
    \label{figure: accuracy vs training data}
\end{figure}

%     -[[ Specific pitfalls of MARS models ]]-
% BASELINE
\textit{MARS baseline}, which was trained on the calibration data of a single recording, performed very badly, as was to be expected, due to the small training set.
% PAPER
\textit{MARS paper} did not perform significantly better, even though it had a larger training data set. 
This was most likely in part due to the fact that the specific data recording setup used to create that model was different from the one used in IAmMuse, something Deep Learning models are often sensitive to.
% FULL CALIB
\textit{MARS full calib} also yielded a bad result, the model seemed to get stuck in a local minima during training. 
It held a static position, which minimized the error, as opposed to trying to dynamically interpret the input data.
This was likely in part due to the specific properties of the calibration data.
The models where MARS was trained on a significant amount of \textit{usage data} (\textit{MARS standard to free} and \textit{MARS partial standard}) performed the best. 
These models were, however, also not perfect, as their output was quite stuttery.
% These models still suffered from the fact that they were very stuttery.
This was almost certainly caused by the stability issue with data from the mmWave Radar, which is discussed in \cref{section: background - millimeter wave radar}.

%     -[[ Conclusion ]]-
The IAmMuse system uses significantly less data and produces significantly better results than similar DL systems.
Granted, IAmMuse tries to solve a more specific problem than MARS, but in many cases, a solid application-specific solution is better than a flaky general-purpose solution.
Many of the current shortcomings of IAmMuse, such as the need for calibration and the limited arm angles, are also not inherent and are likely to be solvable with follow-up research, this is further discussed in \cref{section: conclusion - future work}.
Al in al IAmMuse succeeded in showing the potential of \textbf{algorithmic} human pose estimation systems for millimeter wave radar data.
It was able to circumnavigate the low point density inherent to these chips by using domain knowledge to enhance the data, as well as using other tunable systems to solve issues that were encountered.
The various parts of the IAmMuse pipeline can also be inspected and tuned individually, making it feasible to move this system between different usage environments.

Thus, this thesis has succeeded in all the research challenges that were set out.
\begin{itemize}
    \item 
        An effective algorithmic interpretation method for mmWave radar pointclouds has been created. 
        This method interprets these pointclouds for use in Human Pose Estimation application.
    \item  
        The method created is explainable, as is shown by the explanation provided in \cref{chapter: tracking method}. 
        Furthermore, the system can also be tuned to work in changing circumstances.
    \item 
        The interpretation method provided exceeds the performance of a similar deep learning system, in the form of MARS.
\end{itemize}
With that, the authors believe this research to be a success.


% Mention performance of various Mars models
% With equal training, MARS performs super poorly
% Mars fell into a local maxima with config train
% Well-trained is better over the board
% Well-trained still suffers from similar issues as config train

% Start making a conclusion
% MARS had issues with {stability, certain positions}
% This is most likely due to
% IAmMuse didn't
% Only issue IAmMuse had was {zone specification}.

% Thus, IAmMuse is better.
